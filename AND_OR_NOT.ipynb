{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmOrd4mWJHPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baf7ea70-1fe8-4bf6-89a6-dd26179adb5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the dataset\n",
        "%cd /content/drive/MyDrive/IRWA/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WI3FnTkKS9x",
        "outputId": "7733a02d-8f97-4b2a-b57a-f8a33dc81375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IRWA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def invertedIndex():\n",
        "\n",
        "  dictionary = dict()\n",
        "  directory = os.getcwd()+'/inverted'\n",
        "  files = os.listdir(directory)\n",
        "\n",
        "  #looking at the content\n",
        "  \n",
        "  for file in files:\n",
        "    with open(os.getcwd()+'/inverted/'+file,'r') as f:\n",
        "      words = f.read().lower().split()\n",
        "      for word in words:\n",
        "        if word not in dictionary:\n",
        "          dictionary[word] = [file]\n",
        "        else:\n",
        "          dictionary[word].append(file)\n",
        "  return(dictionary)"
      ],
      "metadata": {
        "id": "ZbvAVbz0KeNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#{'breakthrough': ['Doc1.txt'], 'drug': ['Doc1.txt', 'Doc2.txt'], 'for': ['Doc1.txt', 'Doc3.txt', 'Doc4.txt'], 'schizophrenia': ['Doc1.txt', 'Doc2.txt', 'Doc3.txt', 'Doc4.txt'], 'new': ['Doc2.txt', 'Doc3.txt', 'Doc4.txt'], 'approach': ['Doc3.txt'], 'treatment': ['Doc3.txt'], 'of': ['Doc3.txt'], 'hopes': ['Doc4.txt'], 'patients': ['Doc4.txt']}"
      ],
      "metadata": {
        "id": "9iJ__sdBMfvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AND operation\n",
        "def AND_op(list1,list2):\n",
        "  if((list1) and (list2)):\n",
        "    return set(list1).intersection(list2)\n",
        "  else:\n",
        "    return()\n",
        "\n",
        "II1 = invertedIndex()\n",
        "for key in II1:\n",
        "  if key == 'schizophrenia':\n",
        "    list1 = II1[key]\n",
        "    print('list1: ',list1)\n",
        "  \n",
        "  if key == 'drug':\n",
        "    list2 = II1[key]\n",
        "    print('list2: ',list2)\n",
        "\n",
        "print('Schizophrenia AND Drug: ', AND_op(list1,list2))\n",
        "\n"
      ],
      "metadata": {
        "id": "bHD14Vs_Pl9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b59ed07-1a62-4d16-909f-4af462d59f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list2:  ['Doc1.txt', 'Doc2.txt']\n",
            "list1:  ['Doc1.txt', 'Doc2.txt', 'Doc3.txt', 'Doc4.txt']\n",
            "Schizophrenia AND Drug:  {'Doc2.txt', 'Doc1.txt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OR operation\n",
        "def OR_op(list1,list2):\n",
        "    return set(list1).union(list2)\n",
        "\n",
        "#NOT operation\n",
        "def NOT_op(a):\n",
        "  directory = os.getcwd()+'/inverted'\n",
        "  files = os.listdir(directory)\n",
        "  return set(files).symmetric_difference(a)\n",
        "\n",
        "II2 = invertedIndex()\n",
        "\n",
        "for key in II2:\n",
        "  if key == 'approach':\n",
        "    list3=II2[key]\n",
        "    print('list3: ',list3)\n",
        "  \n",
        "  if key == 'for':\n",
        "    list4=II2[key]\n",
        "    print('list4: ',list4)\n",
        "\n",
        "  if key == 'drug':\n",
        "    list5=II2[key]\n",
        "    print('list5: ',list5)\n",
        "\n",
        "list6=OR_op(list3,list5)\n",
        "print('list6: ',list6)\n",
        "\n",
        "list7=NOT_op(list6)\n",
        "print('list7: ',list7)\n",
        "\n",
        "list8=AND_op(list7,list4)\n",
        "print('for AND NOT(drug OR approach): ',list8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbURvq8kr6DQ",
        "outputId": "f96d48aa-c54c-44d8-b3d3-890431763067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list5:  ['Doc1.txt', 'Doc2.txt']\n",
            "list4:  ['Doc1.txt', 'Doc3.txt', 'Doc4.txt']\n",
            "list3:  ['Doc3.txt']\n",
            "list6:  {'Doc2.txt', 'Doc1.txt', 'Doc3.txt'}\n",
            "list7:  {'Doc4.txt'}\n",
            "for AND NOT(drug OR approach):  {'Doc4.txt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "sw = stopwords.words('english')\n",
        "print(sw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uFIx25QYtp5",
        "outputId": "e21b14f2-fb25-4706-dd30-5162e2437267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sw))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRV7c1nXhD1q",
        "outputId": "13552f85-d7e8-4884-cf3e-6626aad11156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quote = \"Pythoners are very intelligent and work very pythonly and now they are pythoning their way to success.\" \n",
        "tokenized_quote = word_tokenize(quote)\n",
        "print('Tokenized Quote: ',tokenized_quote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8r3rPYOmeDA",
        "outputId": "7dbe2c82-4007-4694-fe94-1d8cd172a677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Quote:  ['Pythoners', 'are', 'very', 'intelligent', 'and', 'work', 'very', 'pythonly', 'and', 'now', 'they', 'are', 'pythoning', 'their', 'way', 'to', 'success', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "refined_quote = []\n",
        "sw.append('.')\n",
        "\n",
        "for tw in tokenized_quote:\n",
        "  if tw not in sw:\n",
        "    refined_quote.append(tw)\n",
        "\n",
        "print('Refined Quote: ',refined_quote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS4fN3GM-Guk",
        "outputId": "cf3cdc8d-d3aa-4585-d0c7-e6fc4dbaab3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refined Quote:  ['Pythoners', 'intelligent', 'work', 'pythonly', 'pythoning', 'way', 'success']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "lancas = LancasterStemmer()\n",
        "snow = SnowballStemmer('english')\n",
        "\n",
        "print(\"{0:20}{1:20}{2:20}{3:20}\".format(\"Refined Quote\",\"Porter Stemmer\",\"lancaster Stemmer\",\"Snowball Stemmer\"))\n",
        "for word in refined_quote:\n",
        "  print(\"{0:20}{1:20}{2:20}{3:20}\".format(word,porter.stem(word),lancas.stem(word),snow.stem(word)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meKLvyrOCPmm",
        "outputId": "29b26ec8-1282-4dc1-8b93-d974b9dd255b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refined Quote       Porter Stemmer      lancaster Stemmer   Snowball Stemmer    \n",
            "Pythoners           python              python              python              \n",
            "intelligent         intellig            intellig            intellig            \n",
            "work                work                work                work                \n",
            "pythonly            pythonli            python              python              \n",
            "pythoning           python              python              python              \n",
            "way                 way                 way                 way                 \n",
            "success             success             success             success             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "port_quote = []\n",
        "lancas_quote = []\n",
        "snow_quote = []\n",
        "\n",
        "for i in refined_quote:\n",
        "  port_quote.append(porter.stem(i))\n",
        "\n",
        "for i in refined_quote:\n",
        "  lancas_quote.append(lancas.stem(i))\n",
        "\n",
        "for i in refined_quote:\n",
        "  snow_quote.append(snow.stem(i))\n",
        "\n",
        "print('port_quote: ',port_quote)\n",
        "print('lancas_quote: ',lancas_quote)\n",
        "print('snow_quote: ',snow_quote)\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo8kgDxMGnor",
        "outputId": "f1781e7e-ce15-4c2f-c17d-c1a239d1d261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "port_quote:  ['python', 'intellig', 'work', 'pythonli', 'python', 'way', 'success']\n",
            "lancas_quote:  ['python', 'intellig', 'work', 'python', 'python', 'way', 'success']\n",
            "snow_quote:  ['python', 'intellig', 'work', 'python', 'python', 'way', 'success']\n"
          ]
        }
      ]
    }
  ]
}